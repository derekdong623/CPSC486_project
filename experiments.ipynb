{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from soft_aggregation_alg import estimate_decomposition\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_v(p: int, r: int, anchor_prob: int, num_anch: int, rng: np.random.Generator):\n",
    "    V = rng.random((p, r))\n",
    "    V /= V.sum(axis=0)[np.newaxis, :]\n",
    "    # Assumption: there is at least one disaggregation anchor state, \n",
    "    # for each meta-state\n",
    "    anchor_indices = rng.permutation(p)\n",
    "    anchor_states = [[] for i in range(r)]\n",
    "    for meta in range(r):\n",
    "        V[anchor_indices[num_anch * meta: num_anch * (meta + 1)], :] *= (1-anchor_prob)\n",
    "        V[anchor_indices[num_anch * meta: num_anch * (meta + 1)], meta] += anchor_prob\n",
    "        anchor_states[meta] += list(anchor_indices[num_anch * meta: num_anch * (meta + 1)])\n",
    "    V /= V.sum(axis=0)\n",
    "    # print(f\"Anchor states: {anchor_indices}\")\n",
    "    return anchor_states, V\n",
    "\n",
    "def generate_n(p: int, r: int, anchor_prob: int, num_anch: int, rng: np.random.Generator, T: int):\n",
    "    start_time = time.time()\n",
    "    U = rng.random((p, r))\n",
    "    U /= U.sum(axis=1)[:, np.newaxis]\n",
    "    assert np.allclose(U.sum(axis=1), 1)\n",
    "    anchor_states, V = generate_v(p, r, anchor_prob, num_anch, rng)\n",
    "    assert np.allclose(V.sum(axis=0), 1)\n",
    "    P = U @ V.T\n",
    "    assert np.allclose(P.sum(axis=1), 1)\n",
    "\n",
    "    # Draw T iterations from the Markov chain with transition matrix P\n",
    "    X = np.random.randint(p)\n",
    "    N = [[0] * p for i in range(p)]\n",
    "    for t in range(T):\n",
    "        next_X = rng.choice(a=p, p=P[X, :])\n",
    "        N[X][next_X] += 1\n",
    "        X = next_X\n",
    "    N = np.array(N)\n",
    "    end_time = time.time()\n",
    "\n",
    "    return U, V, P, N, anchor_states, end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TV(a: np.ndarray, b: np.ndarray):\n",
    "    # Requires a, b to be the same shape\n",
    "    return np.abs(a[:, np.newaxis] - b).sum(axis=2).min(axis=1).sum()\n",
    "\n",
    "def L2(a: np.ndarray, b: np.ndarray, typ='V'):\n",
    "    # Requires a, b to be the same shape\n",
    "    return ((a[:, np.newaxis] - b)**2).sum(axis=2).min(axis=1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 623\n",
    "rng = np.random.default_rng(SEED)\n",
    "r = 6\n",
    "\n",
    "res = {\n",
    "    'n': [],\n",
    "    'p': [],\n",
    "    'r': [],\n",
    "    'anchor_prob': [],\n",
    "    'num_anchors': [],\n",
    "    'TV_err_V': [],\n",
    "    'TV_err_U': [],\n",
    "    'TV_err_P_hat': [],\n",
    "    'TV_err_P': [],\n",
    "    'L2_err_V': [],\n",
    "    'L2_err_U': [],\n",
    "    'L2_err_P_hat': [],\n",
    "    'L2_err_P': [],\n",
    "    'sim_time': [],\n",
    "    'decomp_time': [],\n",
    "    'trial': []\n",
    "}\n",
    "\n",
    "err_func_to_name = {\n",
    "    TV: 'TV_err',\n",
    "    L2: 'L2_err',\n",
    "}\n",
    "t5, t6, t7 = 10**5, 10**6, 10**7\n",
    "for T in [8*t5, t6, 2*t6, 5*t6, t7, 3*t7]:\n",
    "    print(f\"Starting T={T}\")\n",
    "    for anch in [1, 2, 5, 10]:\n",
    "        print(f\"\\tStarting num_anch={anch}\")\n",
    "        for p in [1000]:\n",
    "            for anchor_prob in [1]:\n",
    "                for trial in range(5):\n",
    "                    print(f\"\\t\\tStarting trial={trial}\")\n",
    "                    U, V, P, N, anchor_states, sim_time = generate_n(p, r, anchor_prob, anch, rng, T)\n",
    "\n",
    "                    decomp_start = time.time()\n",
    "                    ret = estimate_decomposition(N, r)\n",
    "                    decomp_end = time.time()\n",
    "\n",
    "                    res['n'].append(T)\n",
    "                    res['p'].append(p)\n",
    "                    res['r'].append(r)\n",
    "                    res['anchor_prob'].append(anchor_prob)\n",
    "                    res['num_anchors'].append(anch)\n",
    "                    res['trial'].append(trial)\n",
    "\n",
    "                    for err_func in [TV, L2]:\n",
    "                        res[f'{err_func_to_name[err_func]}_V'].append(err_func(V.T, ret['V_hat'].T))\n",
    "                        res[f'{err_func_to_name[err_func]}_U'].append(err_func(U, ret['U_hat']))\n",
    "                        res[f'{err_func_to_name[err_func]}_P_hat'].append(err_func(P, ret['P_hat']))\n",
    "                        res[f'{err_func_to_name[err_func]}_P'].append(err_func(P, ret['U_hat'] @ ret['V_hat'].T))\n",
    "\n",
    "                    res['sim_time'].append(sim_time)\n",
    "                    res['decomp_time'].append(decomp_end - decomp_start)\n",
    "res = pd.DataFrame(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
